{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the image\n",
        "image = Image.open('/content/fruits.jpg')\n",
        "\n",
        "# Convert the image to a numpy array if you need to work with numerical data\n",
        "image_array = np.array(image)"
      ],
      "metadata": {
        "id": "ogVD5Q7xBg2R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtKFf8nV5Xt7",
        "outputId": "0296ef16-066b-4d3a-cff5-4e756f769aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1362: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relative error from Practical Coreset is 3.8148776731353693\n",
            "Relative error from Uniformly random Coreset is 1.6206192970904223\n"
          ]
        }
      ],
      "source": [
        "\"\"\"*****************************************************************************************\n",
        "IIIT Delhi License\n",
        "Copyright (c) 2023 Supratim Shit\n",
        "*****************************************************************************************\"\"\"\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.datasets import fetch_kddcup99\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial.distance import cdist\n",
        "import wkpp as wkpp\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "data = image_array\n",
        "data=  make_blobs(n_samples=100,n_features=17)\n",
        "dataset = fetch_kddcup99()\t\t\t\t\t\t\t\t# Fetch kddcup99\n",
        "data = dataset.data\t\t\t\t\t\t\t\t\t\t# Load data\n",
        "data = np.delete(data,[0,1,2,3],1) \t\t\t\t\t\t# Preprocess\n",
        "data = data.astype(float)\t\t\t\t\t\t\t\t# Preprocess\n",
        "data = StandardScaler().fit_transform(data)\t\t\t\t# Preprocess\n",
        "\n",
        "n = np.size(data,0)\t\t\t\t\t\t\t\t\t\t# Number of points in the dataset\n",
        "d = np.size(data,1)\t\t\t\t\t\t\t\t\t\t# Number of dimension/features in the dataset.\n",
        "k = 17\t\t\t\t\t\t\t\t\t\t\t\t\t# Number of clusters (say k = 17)\n",
        "Sample_size = 100\t\t\t\t\t\t\t\t\t\t# Desired coreset size (say m = 100)\n",
        "\n",
        "\n",
        "def D2(data, k):\n",
        "    n_samples, n_features = data.shape\n",
        "    B = np.zeros((k, n_features))\n",
        "    # Randomly choose the first center\n",
        "    B[0] = data[np.random.randint(n_samples)]\n",
        "\n",
        "    for i in range(1, k):\n",
        "        # Calculate the squared Euclidean distances from each data point to the nearest already chosen center\n",
        "        if i == 1:\n",
        "            distances = np.sum((data - B[0])**2, axis=1)\n",
        "        else:\n",
        "            distances = np.min(cdist(data, B[:i])**2, axis=1)\n",
        "\n",
        "        # Normalize distances to get probabilities\n",
        "        total_distance = np.sum(distances)\n",
        "        probabilities = distances / total_distance\n",
        "\n",
        "        # Ensure 'a' is an array of indices from which to sample, and 'p' is the probabilities array\n",
        "        selected_idx = np.random.choice(np.arange(n_samples), p=probabilities)\n",
        "        B[i] = data[selected_idx]\n",
        "\n",
        "    return B \t\t\t\t\t\t\t\t\t\t# Returns B from Algo-1.\n",
        "\n",
        "centers = D2(data,k)\t\t\t\t\t\t\t\t\t# Call D2-Sampling (D2())\n",
        "\n",
        "def Sampling(data, k, centers, Sample_size):\n",
        "    # Assume the sensitivities are calculated based on the nearest center distances\n",
        "    distances = np.min(cdist(data, centers) ** 2, axis=1)\n",
        "    total_distance = np.sum(distances)\n",
        "    sensitivities = distances / total_distance\n",
        "    sampling_probabilities = sensitivities / np.sum(sensitivities)\n",
        "    sample_indices = np.random.choice(data.shape[0], size=Sample_size, replace=True, p=sampling_probabilities)\n",
        "    coreset = data[sample_indices]\n",
        "    weight = np.ones(Sample_size) * (1 / sampling_probabilities[sample_indices]) * (1 / Sample_size)\n",
        "\n",
        "    return coreset, weight \t\t\t\t\t\t\t\t# Return coreset points and its weights.\n",
        "\n",
        "coreset, weight = Sampling(data,k,centers,Sample_size)\t# Call coreset construction algorithm (Sampling())\n",
        "\n",
        "#---Running KMean Clustering---#\n",
        "fkmeans = KMeans(n_clusters=k,init='k-means++')\n",
        "fkmeans.fit_predict(data)\n",
        "\n",
        "#----Practical Coresets performance----#\n",
        "Coreset_centers, _ = wkpp.kmeans_plusplus_w(coreset, k, w=weight, n_local_trials=100)\t\t\t\t\t\t# Run weighted kMeans++ on coreset points\n",
        "wt_kmeansclus = KMeans(n_clusters=k, init=Coreset_centers, max_iter=10).fit(coreset,sample_weight = weight)\t# Run weighted KMeans on the coreset, using the inital centers from the above line.\n",
        "Coreset_centers = wt_kmeansclus.cluster_centers_\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Compute cluster centers\n",
        "coreset_cost = np.sum(np.min(cdist(data,Coreset_centers)**2,axis=1))\t\t\t\t\t\t\t\t\t\t# Compute clustering cost from the above centers\n",
        "reative_error_practicalCoreset = abs(coreset_cost - fkmeans.inertia_)/fkmeans.inertia_\t\t\t\t\t\t# Computing relative error from practical coreset, here fkmeans.inertia_ is the optimal cost on the complete data.\n",
        "\n",
        "#-----Uniform Sampling based Coreset-----#\n",
        "tmp = np.random.choice(range(n),size=Sample_size,replace=False)\n",
        "sample = data[tmp][:]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Uniform sampling\n",
        "sweight = n*np.ones(Sample_size)/Sample_size \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Maintain appropriate weight\n",
        "sweight = sweight/np.sum(sweight)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Normalize weight to define a distribution\n",
        "\n",
        "#-----Uniform Samling based Coreset performance-----#\n",
        "wt_kmeansclus = KMeans(n_clusters=k, init='k-means++', max_iter=10).fit(sample,sample_weight = sweight)\t\t# Run KMeans on the random coreset\n",
        "Uniform_centers = wt_kmeansclus.cluster_centers_\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Compute cluster centers\n",
        "uniform_cost = np.sum(np.min(cdist(data,Uniform_centers)**2,axis=1))\t\t\t\t\t\t\t\t\t\t# Compute clustering cost from the above centers\n",
        "reative_error_unifromCoreset = abs(uniform_cost - fkmeans.inertia_)/fkmeans.inertia_\t\t\t\t\t\t# Computing relative error from random coreset, here fkmeans.inertia_ is the optimal cost on the full data.\n",
        "\n",
        "\n",
        "print(\"Relative error from Practical Coreset is\",reative_error_practicalCoreset)\n",
        "print(\"Relative error from Uniformly random Coreset is\",reative_error_unifromCoreset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFp4WadfUp5k",
        "outputId": "7565c999-524a-49b1-8c0a-18481482c694"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Step 1: Cluster the image data using KMeans\n",
        "fkmeans = KMeans(n_clusters=k, init='k-means++')\n",
        "cluster_labels = fkmeans.fit_predict(image_array.reshape(-1, 3))  # Reshape image for KMeans\n",
        "\n",
        "# Step 2: Assign each pixel to its nearest cluster center\n",
        "cluster_centers = fkmeans.cluster_centers_\n",
        "segmented_image_data = cluster_centers[cluster_labels]\n",
        "\n",
        "# Step 3: Reshape the modified data back into the image shape\n",
        "segmented_image = segmented_image_data.reshape(image_array.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSl1i13A1jVR",
        "outputId": "65e68346-8c03-42b5-b576-eb4882d60277"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image1=Image.fromarray(segmented_image_data.astype(np.uint8))\n",
        "scaled_segmented_image_data=np.clip(image1,0,255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "HmJ2tdktznkh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Convert the data type of segmented_image_data to uint8\n",
        "segmented_image_data_uint8 = segmented_image_data.astype(np.uint8)\n",
        "\n",
        "# Reshape the segmented image data to match the shape of the original image array\n",
        "segmented_image_data_reshaped = segmented_image_data_uint8.reshape(image_array.shape)\n",
        "\n",
        "# Convert the numpy array to an image\n",
        "image = Image.fromarray(segmented_image_data_reshaped)\n",
        "\n",
        "# Check the mode of the image\n",
        "print(\"Image mode:\", image.mode)\n",
        "\n",
        "# If the mode is not compatible with PNG, convert it to RGB or RGBA\n",
        "if image.mode != 'RGB' and image.mode != 'RGBA':\n",
        "    image = image.convert('RGB')  # or 'RGBA' if you have an alpha channel\n",
        "\n",
        "# Save the image to a file\n",
        "image.save(\"fruits_segmented.png\")\n",
        "\n",
        "# Optionally, display the image\n",
        "image.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf1H06sidlgq",
        "outputId": "8823b649-1635-4e5d-b1c5-e235547c277c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image mode: RGB\n"
          ]
        }
      ]
    }
  ]
}